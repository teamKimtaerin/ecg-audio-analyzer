# Backend Server í†µí•© ê°€ì´ë“œ

## ê°œìš”
ML Serverì˜ API ë³€ê²½ì‚¬í•­ì— ë§ì¶° Backend Serverì—ì„œ ìˆ˜ì •í•´ì•¼ í•  ë¶€ë¶„ë“¤ì„ ì •ë¦¬í•œ ë¬¸ì„œì…ë‹ˆë‹¤.

## ML Server ë³€ê²½ì‚¬í•­ ìš”ì•½

### 1. ì½œë°± URL ë³€ê²½
- **ê¸°ì¡´**: `/api/v1/ml/ml-results`
- **ë³€ê²½**: `/api/upload-video/result`

### 2. ìš”ì²­/ì‘ë‹µ êµ¬ì¡° ê°œì„ 
- **ProcessVideoRequest**: ì¶”ê°€ íŒŒë¼ë¯¸í„° ì§€ì›
- **ProcessVideoResponse**: status_url í•„ë“œ ì¶”ê°€
- **ê²°ê³¼ ë°ì´í„°**: ë°±ì—”ë“œ ê¸°ëŒ€ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡° ë³€ê²½

## Backend Server í•„ìˆ˜ ìˆ˜ì •ì‚¬í•­

### 1. ML Server í˜¸ì¶œ ì‹œ ì¶”ê°€ íŒŒë¼ë¯¸í„° ì „ì†¡

**íŒŒì¼**: `ml_video.py` (ë˜ëŠ” ML Server í˜¸ì¶œ ë¶€ë¶„)

```python
# ê¸°ì¡´ ì½”ë“œ
payload = {
    "job_id": job_id,
    "video_url": video_url
}

# ìˆ˜ì •ëœ ì½”ë“œ
payload = {
    "job_id": job_id,
    "video_url": video_url,
    "fastapi_base_url": FASTAPI_BASE_URL,  # ë™ì  ì½œë°± URL ì œê³µ
    "language": language or "auto",         # ì–¸ì–´ ì„¤ì • (ê¸°ë³¸ê°’: auto)
    "enable_gpu": True,                     # GPU ì‚¬ìš© ì—¬ë¶€
    "emotion_detection": True,              # ê°ì • ë¶„ì„ ì—¬ë¶€  
    "max_workers": 4                        # ìµœëŒ€ ì›Œì»¤ ìˆ˜
}
```

**í™˜ê²½ë³€ìˆ˜ ì¶”ê°€**:
```bash
FASTAPI_BASE_URL=http://your-backend-server:8000  # Backend Server ì£¼ì†Œ
```

### 2. ML Server ì‘ë‹µ ì²˜ë¦¬ ìˆ˜ì •

**ìƒˆë¡œìš´ ì‘ë‹µ í˜•ì‹**:
```python
response = {
    "job_id": "123e4567-e89b-12d3-a456-426614174000",
    "status": "processing",              # "accepted" â†’ "processing"ìœ¼ë¡œ ë³€ê²½
    "message": "ë¹„ë””ì˜¤ ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
    "status_url": "/api/upload-video/status/{job_id}",  # ìƒˆë¡œ ì¶”ê°€ëœ í•„ë“œ
    "estimated_time": 300
}
```

**Backend ì²˜ë¦¬ ì½”ë“œ ìˆ˜ì •**:
```python
# ML Server ì‘ë‹µ ì²˜ë¦¬
if response.status_code == 200:
    result = response.json()
    
    # ìƒˆë¡œìš´ í•„ë“œ ì²˜ë¦¬
    status_url = result.get("status_url")  # ì„ íƒì  ì²˜ë¦¬
    
    # Job ìƒíƒœë¥¼ "processing"ìœ¼ë¡œ ì—…ë°ì´íŠ¸
    await update_job_status(
        job_id=result["job_id"],
        status=result["status"],  # "processing"
        message=result["message"]
    )
else:
    # ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
    await update_job_status(
        job_id, "failed", 
        error_message=f"ML Server returned {response.status_code}"
    )
```

### 3. ì½œë°± ì—”ë“œí¬ì¸íŠ¸ í™•ì¸

ML ServerëŠ” ì´ì œ `/api/upload-video/result`ë¡œ ì½œë°±ì„ ì „ì†¡í•©ë‹ˆë‹¤.

**í™•ì¸ì‚¬í•­**:
- í•´ë‹¹ ì—”ë“œí¬ì¸íŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
- ì½œë°± ë°ì´í„° êµ¬ì¡°ê°€ ML Serverê°€ ì „ì†¡í•˜ëŠ” í˜•ì‹ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸

**ML Server ì½œë°± ë°ì´í„° êµ¬ì¡°**:
```json
{
  "job_id": "123e4567-e89b-12d3-a456-426614174000",
  "status": "processing|completed|failed",
  "progress": 0-100,
  "message": "ì²˜ë¦¬ ìƒíƒœ ë©”ì‹œì§€",
  "result": {  // statusê°€ "completed"ì¸ ê²½ìš°ì—ë§Œ í¬í•¨
    "text": "ì „ì²´ transcription í…ìŠ¤íŠ¸",
    "segments": [...],
    "language": "en|ko|auto",
    "duration": 120.5,
    "metadata": {
      "model_version": "whisperx-base",
      "processing_time": 45.2,
      "unique_speakers": 3,
      "total_segments": 42
    }
  },
  "error_message": "ì—ëŸ¬ ë©”ì‹œì§€",  // statusê°€ "failed"ì¸ ê²½ìš°ì—ë§Œ í¬í•¨
  "error_code": "ERROR_CODE"     // statusê°€ "failed"ì¸ ê²½ìš°ì—ë§Œ í¬í•¨
}
```

### 4. íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¦ê°€

**í™˜ê²½ë³€ìˆ˜ ìˆ˜ì •**:
```bash
# ê¸°ì¡´
ML_API_TIMEOUT=30

# ê¶Œì¥ ë³€ê²½
ML_API_TIMEOUT=300  # 5ë¶„ (ëŒ€ìš©ëŸ‰ ë¹„ë””ì˜¤ ì²˜ë¦¬ ê³ ë ¤)
```

**ì½”ë“œ ì ìš©**:
```python
ML_API_TIMEOUT = int(os.getenv("ML_API_TIMEOUT", "300"))  # ê¸°ë³¸ 5ë¶„

# ML Server í˜¸ì¶œ ì‹œ
response = await http_client.post(
    f"{MODEL_SERVER_URL}/api/upload-video/process-video",
    json=payload,
    timeout=ML_API_TIMEOUT  # ì ìš©
)
```

### 5. ì—ëŸ¬ í•¸ë“¤ë§ ê°œì„ 

```python
try:
    response = await call_ml_server(payload)
    
    if response.status_code != 200:
        # ML Serverê°€ 200ì´ ì•„ë‹Œ ìƒíƒœ ë°˜í™˜ ì‹œ ì²˜ë¦¬
        error_detail = response.json() if response.content else {}
        await update_job_status(
            job_id, "failed",
            error_message=f"ML Server error: {error_detail.get('message', 'Unknown error')}",
            error_code=error_detail.get('error', {}).get('code', 'ML_SERVER_ERROR')
        )
        return
        
except requests.exceptions.Timeout:
    await update_job_status(
        job_id, "failed",
        error_message="ML Server processing timeout",
        error_code="TIMEOUT_ERROR"
    )
    
except requests.exceptions.RequestException as e:
    await update_job_status(
        job_id, "failed",
        error_message=f"ML Server connection error: {str(e)}",
        error_code="CONNECTION_ERROR"
    )
```

## ê¶Œì¥ êµ¬í˜„ ìˆœì„œ

### Phase 1: í•„ìˆ˜ ìˆ˜ì •ì‚¬í•­ (ì¦‰ì‹œ ì ìš©)
1. âœ… ì½œë°± URLì´ `/api/upload-video/result`ë¡œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
2. âœ… ML Server í˜¸ì¶œ ì‹œ `fastapi_base_url` íŒŒë¼ë¯¸í„° ì¶”ê°€
3. âœ… íƒ€ì„ì•„ì›ƒ ì„¤ì •ì„ 300ì´ˆë¡œ ì¦ê°€

### Phase 2: ì‘ë‹µ ì²˜ë¦¬ ê°œì„ 
1. âœ… `status_url` í•„ë“œ ì²˜ë¦¬ ì¶”ê°€
2. âœ… `status` í•„ë“œê°€ "processing"ìœ¼ë¡œ ë³€ê²½ëœ ê²ƒ ë°˜ì˜
3. âœ… ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”

### Phase 3: ì¶”ê°€ ê¸°ëŠ¥ í™œìš©
1. ğŸ”„ `language` íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©ì ì„¤ì •ì— ë”°ë¼ ì „ë‹¬
2. ğŸ”„ `enable_gpu`, `emotion_detection` ë“± ì„¤ì • ì˜µì…˜ ì¶”ê°€
3. ğŸ”„ ìƒˆë¡œìš´ ê²°ê³¼ ë°ì´í„° êµ¬ì¡° í™œìš© (metadata ì •ë³´ ë“±)

## í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

### 1. ë¡œì»¬ í…ŒìŠ¤íŠ¸
```bash
# ML Server í—¬ìŠ¤ì²´í¬
curl http://ml-server:8080/health

# Backend â†’ ML Server í†µì‹  í…ŒìŠ¤íŠ¸
curl -X POST http://backend-server:8000/api/upload-video/request-process \
  -H "Content-Type: application/json" \
  -d '{"fileKey": "test-video.mp4"}'
```

### 2. í†µí•© í…ŒìŠ¤íŠ¸
1. ì‹¤ì œ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
2. ì½œë°± ìˆ˜ì‹  í™•ì¸
3. ê²°ê³¼ ë°ì´í„° êµ¬ì¡° ê²€ì¦
4. ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ, ì—°ê²° ì‹¤íŒ¨ ë“±)

### 3. ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
- ML Server ì‘ë‹µ ì‹œê°„
- ì½œë°± ìˆ˜ì‹  ì„±ê³µë¥   
- ì „ì²´ ì²˜ë¦¬ ì™„ë£Œìœ¨
- ì—ëŸ¬ ë°œìƒ ë¹ˆë„ ë° ìœ í˜•

## í˜¸í™˜ì„± ì •ë³´

### í•˜ìœ„ í˜¸í™˜ì„±
- ê¸°ì¡´ ì½œë°± URL(`/api/v1/ml/ml-results`)ì€ ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
- ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„°ë“¤ì€ ëª¨ë‘ ì„ íƒì ì´ë¯€ë¡œ ê¸°ì¡´ ìš”ì²­ë„ ë™ì‘í•¨

### API ë²„ì „
- ML Server API ë²„ì „: v1.1
- ë³€ê²½ ë‚ ì§œ: 2024-12-28
- í˜¸í™˜ì„± ë³´ì¥: 2025ë…„ 3ì›”ê¹Œì§€

## ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

**1. ì½œë°±ì´ ìˆ˜ì‹ ë˜ì§€ ì•ŠìŒ**
- ì½œë°± URLì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸: `/api/upload-video/result`
- `fastapi_base_url`ì´ ì˜¬ë°”ë¥´ê²Œ ì „ë‹¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
- ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± í™•ì¸

**2. íƒ€ì„ì•„ì›ƒ ì—ëŸ¬**
- `ML_API_TIMEOUT` í™˜ê²½ë³€ìˆ˜ë¥¼ 300ì´ˆë¡œ ì„¤ì •
- ëŒ€ìš©ëŸ‰ ë¹„ë””ì˜¤ì˜ ê²½ìš° ë” ê¸´ íƒ€ì„ì•„ì›ƒ ê³ ë ¤

**3. ì˜ëª»ëœ ì‘ë‹µ êµ¬ì¡°**
- ML Server ë²„ì „ì´ ìµœì‹ ì¸ì§€ í™•ì¸
- ì½œë°± ë°ì´í„° íŒŒì‹± ì½”ë“œ ì ê²€

### ë¡œê·¸ í™•ì¸
```bash
# ML Server ë¡œê·¸
sudo journalctl -u ml-server -f

# Backend ë¡œê·¸ì—ì„œ ML Server ê´€ë ¨ ë¡œê·¸ í•„í„°ë§
grep "ML Server\|process-video" /var/log/backend.log
```

---

**ë¬¸ì˜ì‚¬í•­**: ML Server ê´€ë ¨ ì´ìŠˆëŠ” ê°œë°œíŒ€ì— ë¬¸ì˜í•˜ì„¸ìš”.
**ì—…ë°ì´íŠ¸**: ì´ ë¬¸ì„œëŠ” ML Server ë³€ê²½ì‚¬í•­ì— ë”°ë¼ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.