# ===================================================================
# ECG Audio Analyzer - EC2 Deep Learning AMI Dependencies
# API 서버 운영에 최적화된 버전 (Python 3.10+)
# 중요: 이 파일은 EC2 Deep Learning AMI와 같이 PyTorch가 사전 설치된
#       환경에서 사용하는 것을 전제로 합니다.
# ===================================================================

# --- Core System & ML ---
numpy>=2.0.2,<3.0
scipy>=1.10.0,<2.0
einops>=0.7.0,<1.0
omegaconf>=2.3.0,<3.0

# --- FastAPI Server ---
fastapi>=0.104.0,<1.0
uvicorn[standard]>=0.24.0,<1.0
requests>=2.31.0,<3.0
httpx>=0.25.0,<1.0
aiofiles>=23.2.0,<24.0

# --- Audio Processing ---
librosa>=0.10.1,<1.0
soundfile>=0.12.1,<1.0
ffmpeg-python>=0.2.0,<1.0

# --- Speech Recognition & Diarization ---
# WhisperX는 GitHub에서 직접 설치합니다. (설치 명령어는 아래 참고)
faster-whisper>=1.0.0,<2.0
openai-whisper>=20231117
pyannote.audio>=3.1.0,<3.4   # pytorch-lightning이 필요 없는 3.3 이전 버전 사용 권장
speechbrain>=0.5.16,<1.0
ctranslate2<4.5.0            # faster-whisper 호환성

# --- PyTorch (WhisperX 3.4.2 requirements) ---
torch>=2.5.1
torchaudio>=2.5.1
# torchvision은 필요시 추가

# --- Hugging Face Libraries ---
huggingface-hub>=0.18.0,<1.0
datasets>=2.14.0,<3.0
accelerate>=0.24.0,<1.0
transformers>=4.36.0,<5.0

# --- Utilities & Cloud ---
psutil>=5.9.0,<6.0
python-dotenv>=1.0.0,<2.0
structlog>=23.2.0,<24.0
pydantic>=2.5.0,<3.0
boto3>=1.34.0,<2.0
yt-dlp>=2023.12.30

# --- Additional ML Dependencies ---
einops>=0.7.0,<1.0        # Tensor operations
pytorch-metric-learning>=1.7.3,<2.0
torch-audiomentations>=0.12.0,<1.0
torchmetrics>=0.11.4,<1.0

# --- GPU Monitoring (Optional) ---
nvidia-ml-py3>=7.352.0
gpustat>=1.1.0
