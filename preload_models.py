#!/usr/bin/env python3
"""
Preload models with proper HTTP 301 handling
(v4 - Production ready with fallbacks)
"""
import os
import sys
import torch
import urllib.request
from pathlib import Path

# HTTP 301 í•¸ë“¤ëŸ¬ ì„¤ì •
class SmartRedirectHandler(urllib.request.HTTPRedirectHandler):
    def http_error_301(self, req, fp, code, msg, headers):
        result = urllib.request.HTTPRedirectHandler.http_error_301(
            self, req, fp, code, msg, headers)
        return result
    
    def http_error_302(self, req, fp, code, msg, headers):
        # 302ë„ ì²˜ë¦¬ (ì„ì‹œ ì´ë™)
        result = urllib.request.HTTPRedirectHandler.http_error_302(
            self, req, fp, code, msg, headers)
        return result

opener = urllib.request.build_opener(SmartRedirectHandler)
urllib.request.install_opener(opener)

# íŒ¨ì¹˜ í›„ import
import whisperx
from pyannote.audio import Pipeline

def ensure_cache_dirs():
    """ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    dirs = [
        "/root/.cache/whisper",
        "/root/.cache/huggingface/hub",
        "/root/.cache/torch/hub"
    ]
    for d in dirs:
        Path(d).mkdir(parents=True, exist_ok=True)

def preload_models():
    ensure_cache_dirs()
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    compute_type = "float16" if device == "cuda" else "float32"
    hf_token = os.environ.get('HF_TOKEN')
    
    print(f"ğŸ® Device: {device}, Compute: {compute_type}")
    
    # 1. WhisperX - ì—¬ëŸ¬ ë°©ë²• ì‹œë„
    success = False
    try:
        print("ğŸ“¥ Loading WhisperX model...")
        model = whisperx.load_model("large-v2", device=device, compute_type=compute_type)
        del model
        print("âœ“ WhisperX cached")
        success = True
    except Exception as e:
        print(f"âš  Method 1 failed: {e}")
    
    if not success:
        # Fallback: wget
        print("ğŸ”„ Trying direct download...")
        ret = os.system("wget -nc -q -P /root/.cache/whisper https://openaipublic.azureedge.net/main/whisper/models/large-v2.pt")
        if ret == 0:
            print("âœ“ WhisperX downloaded via wget")
        else:
            print("âŒ WhisperX download failed completely")
    
    # 2. Pyannote - ê°„ë‹¨í•˜ê²Œ
    if hf_token:
        try:
            print("ğŸ“¥ Loading Pyannote...")
            pipeline = Pipeline.from_pretrained(
                "pyannote/speaker-diarization",
                use_auth_token=hf_token
            )
            del pipeline
            print("âœ“ Pyannote cached")
        except:
            print("âš  Pyannote skipped (version mismatch is OK)")
    
    # 3. Alignment ëª¨ë¸ (ê¸°ì¡´ ì½”ë“œ)
    print("ğŸ“¥ Loading alignment models...")
    try:
        for lang in ['en', 'ko', 'ja']:  # í•µì‹¬ ì–¸ì–´ë§Œ
            try:
                model, metadata = whisperx.load_align_model(lang, device)
                del model, metadata
                print(f"  âœ“ {lang} alignment cached")
            except Exception as e:
                print(f"  âš  {lang} failed: {e}")
    except:
        print("âš  Alignment models partial success")
    
    print("âœ… Preloading completed")

if __name__ == "__main__":
    preload_models()
    sys.exit(0)