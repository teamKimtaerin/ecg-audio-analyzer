# Stage 1: Base image with common dependencies
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 AS base

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    python3.10 \
    python3.10-venv \
    python3-pip \
    ffmpeg \
    git \
    libgl1 && \
    rm -rf /var/lib/apt/lists/*

# Update pip
RUN python3.10 -m pip install --no-cache-dir --upgrade pip


# Stage 2: Test stage to run checks
FROM base AS test

WORKDIR /app

# Copy requirements to install dependencies
RUN python3.10 -m pip install --no-cache-dir -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118

# Install linting tools
RUN python3.10 -m pip install --no-cache-dir ruff black

# Copy the rest of the application code
COPY . .

# Run checks
# The user's pyproject.toml excludes ml_api_server.py from ruff, so we respect that.
RUN ruff check .
# Black check runs on all files.
RUN black --check .


# Stage 3: Production stage for the final image
FROM base AS production

# Create a non-root user and set working directory
RUN useradd --create-home appuser
WORKDIR /home/appuser/app

# Copy project requirements first to leverage Docker layer caching
COPY requirements.txt .

# Install Python dependencies
RUN python3.10 -m pip install --no-cache-dir -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118

# Copy the rest of the application code
COPY . .

# Change ownership to the app user
RUN chown -R appuser:appuser /home/appuser/app

# Switch to the non-root user
USER appuser

# Expose the port the app runs on
EXPOSE 8080

# Command to run the application
CMD ["python3.10", "ml_api_server.py", "--host", "0.0.0.0", "--port", "8080"]