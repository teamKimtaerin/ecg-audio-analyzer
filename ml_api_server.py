import sys
from pathlib import Path
import logging
import os
import warnings
from typing import Dict, Any, Optional
from datetime import datetime
import tempfile
import uuid
import re

from dotenv import load_dotenv
load_dotenv()
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Suppress warnings
warnings.filterwarnings("ignore", category=UserWarning)

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import requests
import boto3

from src.utils.logger import get_logger
from src.pipeline.manager import PipelineManager
from config.base_settings import BaseConfig, ProcessingConfig

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="ECG Model Server",
    description="EC2 ML ì„œë²„ - ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ë¶„ì„ API",
    version="1.0.0",
)

# CORS ì„¤ì • ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # í”„ë¡ íŠ¸ì—”ë“œ
        "http://localhost:8000",  # ë°±ì—”ë“œ
        "http://ecg-project-pipeline-dev-alb-1703405864.us-east-1.elb.amazonaws.com",  # Fargate ë°±ì—”ë“œ
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# AWS S3 ë° Backend ì„¤ì •
s3_client = boto3.client("s3")
S3_BUCKET = os.getenv("S3_BUCKET_NAME", os.getenv("S3_BUCKET", ""))
# í”„ë¡œë•ì…˜ URL ìš°ì„ , ì—†ìœ¼ë©´ ê°œë°œ URL ì‚¬ìš©
FASTAPI_BASE_URL = os.getenv("FASTAPI_BASE_URL", "")  # https://ho-it.site
BACKEND_URL = os.getenv("BACKEND_URL", "")  # Fargate ê°œë°œ URL
DEFAULT_CALLBACK_URL = FASTAPI_BASE_URL or BACKEND_URL
ENABLE_CALLBACKS = bool(DEFAULT_CALLBACK_URL and DEFAULT_CALLBACK_URL.strip())

# In-memory job tracking
jobs = {}

# ì¤‘ë³µ ì½œë°± ë°©ì§€ë¥¼ ìœ„í•œ ì™„ë£Œ ì‘ì—… ì¶”ì 
completed_jobs = set()
failed_jobs = set()

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)


# ========== Pydantic Models ==========


class ProcessVideoRequest(BaseModel):
    """Backend í˜¸í™˜ ë¹„ë””ì˜¤ ì²˜ë¦¬ ìš”ì²­"""

    job_id: str
    video_url: str
    # ë°±ì—”ë“œì—ì„œ ë³´ë‚´ëŠ” ì¶”ê°€ í•„ë“œë“¤
    fastapi_base_url: Optional[str] = None  # ë™ì  ì½œë°± URL
    enable_gpu: bool = True
    emotion_detection: bool = True
    language: str = "auto"
    max_workers: int = 4


class ProcessVideoResponse(BaseModel):
    """Backend í˜¸í™˜ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‘ë‹µ"""

    job_id: str
    status: str
    message: str
    status_url: Optional[str] = None  # ì¶”ê°€: ìƒíƒœ ì¡°íšŒ URL
    estimated_time: Optional[int] = 300


class MLProgressCallback(BaseModel):
    """ML ì§„í–‰ ìƒí™© ì½œë°±"""

    job_id: str
    status: str  # processing, completed, failed
    progress: int  # 0-100
    message: Optional[str] = None
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    error_code: Optional[str] = None


class TranscribeRequest(BaseModel):
    """ë°±ì—”ë“œ í˜¸í™˜ ì „ì‚¬ ìš”ì²­"""

    video_path: str  # Deprecated: í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
    audio_path: Optional[str] = None  # ìƒˆë¡œìš´ í•„ë“œ: S3 ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
    video_url: Optional[str] = None
    enable_gpu: bool = True
    emotion_detection: bool = True
    language: str = "en"


class BackendTranscribeResponse(BaseModel):
    """ìƒì„¸ ë¶„ì„ ì‘ë‹µ"""

    success: bool
    metadata: Optional[Dict[str, Any]] = None
    speakers: Optional[Dict[str, Any]] = None
    segments: Optional[list] = None
    processing_time: float
    error: Optional[str] = None
    error_code: Optional[str] = None


# ========== Helper Functions ==========


def create_pipeline(language: str = "en") -> PipelineManager:
    return PipelineManager(
        base_config=BaseConfig(),
        processing_config=ProcessingConfig(),
        language=language,
    )


async def send_callback(
    job_id: str,
    status: str,
    progress: int,
    message: str = "",
    result: Optional[Dict] = None,
    error_message: Optional[str] = None,
    error_code: Optional[str] = None,
    callback_base_url: Optional[str] = None,
):
    """Send progress/error callback to backend"""
    # ì¤‘ë³µ ì½œë°± ë°©ì§€ ì²´í¬
    if status == "completed" and job_id in completed_jobs:
        logger.debug(f"ì´ë¯¸ ì™„ë£Œëœ ì‘ì—… ì½œë°± ìŠ¤í‚µ: {job_id}")
        return
    elif status == "failed" and job_id in failed_jobs:
        logger.debug(f"ì´ë¯¸ ì‹¤íŒ¨í•œ ì‘ì—… ì½œë°± ìŠ¤í‚µ: {job_id}")
        return

    # ë™ì  ì½œë°± URL ê²°ì • (ìš°ì„ ìˆœìœ„: ìš”ì²­ ì œê³µ URL > FASTAPI_BASE_URL > BACKEND_URL)
    base_url = callback_base_url or DEFAULT_CALLBACK_URL
    if not base_url or not base_url.strip():
        logger.debug(f"No callback URL configured - {status}: {message} ({progress}%)")
        return

    try:
        payload = MLProgressCallback(
            job_id=job_id,
            status=status,
            progress=progress,
            message=message or "ì²˜ë¦¬ ì¤‘...",
            result=result,
            error_message=error_message,
            error_code=error_code,
        ).model_dump()

        # ë°±ì—”ë“œ API ê²½ë¡œì— ë§ì¶° ìˆ˜ì • (ê¸°ì¡´: /api/v1/ml/ml-results)
        callback_endpoint = f"{base_url}/api/upload-video/result"

        response = requests.post(
            callback_endpoint,
            json=payload,
            headers={"Content-Type": "application/json", "User-Agent": "ML-Server/1.0"},
            timeout=30 if result else 10,
        )

        if response.status_code == 200:
            # ë°±ì—”ë“œ ì‘ë‹µ ì²˜ë¦¬
            try:
                result_data = response.json()
                if result_data.get("status") == "ignored":
                    logger.info(
                        f"ì½œë°±ì´ ë¬´ì‹œë¨ - Job ID: {job_id}, "
                        f"ì´ìœ : {result_data.get('reason', 'unknown')}"
                    )
                    # ì´ë¯¸ ì™„ë£Œ/ì‹¤íŒ¨í•œ ì‘ì—…ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìƒíƒœ ì¶”ì ì— ì¶”ê°€
                    if status == "completed":
                        completed_jobs.add(job_id)
                    elif status == "failed":
                        failed_jobs.add(job_id)
                else:
                    logger.info(
                        f"Callback sent to {callback_endpoint}: {status} - {message} ({progress}%)"
                    )
                    # ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì™„ë£Œ/ì‹¤íŒ¨ ìƒíƒœ ì¶”ì 
                    if status == "completed":
                        completed_jobs.add(job_id)
                    elif status == "failed":
                        failed_jobs.add(job_id)
            except:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¡œê¹…
                logger.info(
                    f"Callback sent to {callback_endpoint}: {status} - {message} ({progress}%)"
                )
        elif response.status_code == 422:
            # ë°±ì—”ë“œ ê²€ì¦ ì‹¤íŒ¨ ì²˜ë¦¬
            try:
                error_detail = response.json()
                if "Frontend API Misuse" in str(error_detail.get("detail", {})):
                    logger.warning("ë°±ì—”ë“œê°€ í”„ë¡ íŠ¸ì—”ë“œ ì˜¤ìš©ì„ ê°ì§€í•¨ - ML ì„œë²„ëŠ” ì •ìƒ")
                else:
                    logger.error(f"ì½œë°± ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨ - Job ID: {job_id}, Error: {error_detail}")
            except:
                logger.error(f"422 ì—ëŸ¬ - Job ID: {job_id}, Response: {response.text}")
        else:
            logger.warning(
                f"Callback failed to {callback_endpoint}: {response.status_code} - {response.text}"
            )

    except Exception as e:
        logger.error(f"Callback error to {base_url}: {str(e)}")


async def download_from_url(
    url: str, job_id: str, callback_base_url: Optional[str] = None
) -> str:
    """URLì—ì„œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ë¡œì»¬ íŒŒì¼ í™•ì¸"""
    try:
        # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ì§€ í™•ì¸
        local_path = Path(url)
        if local_path.exists():
            logger.info(f"ë¡œì»¬ íŒŒì¼ ì‚¬ìš©: {url}")
            await send_callback(
                job_id,
                "processing",
                10,
                "ë¡œì»¬ íŒŒì¼ í™•ì¸ ì™„ë£Œ",
                callback_base_url=callback_base_url,
            )
            return str(local_path.absolute())

        # URL ë‹¤ìš´ë¡œë“œ
        await send_callback(
            job_id,
            "processing",
            5,
            "ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹œì‘...",
            callback_base_url=callback_base_url,
        )

        # S3 URLì¸ì§€ í™•ì¸í•˜ê³  boto3ë¡œ ë‹¤ìš´ë¡œë“œ
        if url.startswith("https://") and ".s3." in url:
            # S3 URL íŒŒì‹±: https://bucket.s3.region.amazonaws.com/key
            s3_pattern = r"https://([^.]+)\.s3\.([^.]+)\.amazonaws\.com/(.+)"
            match = re.match(s3_pattern, url)
            
            if match:
                bucket_name = match.group(1)
                key = match.group(3)
                
                logger.info(f"S3ì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œì‘: s3://{bucket_name}/{key}")
                
                # ì„ì‹œ íŒŒì¼ ìƒì„± (with ë¸”ë¡ ë°–ì—ì„œ)
                temp_file = tempfile.NamedTemporaryFile(suffix=".mp4", delete=False)
                temp_file.close()  # íŒŒì¼ í•¸ë“¤ ë‹«ê¸°
                
                # boto3ë¡œ S3ì—ì„œ ë‹¤ìš´ë¡œë“œ
                s3_client.download_file(bucket_name, key, temp_file.name)
                
                await send_callback(
                    job_id,
                    "processing",
                    10,
                    "S3ì—ì„œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ",
                    callback_base_url=callback_base_url,
                )
                
                logger.info(f"S3 ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {temp_file.name}")
                return temp_file.name

        # ì¼ë°˜ HTTP URL ì²˜ë¦¬
        with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as temp_file:
            response = requests.get(url, stream=True, timeout=60)
            response.raise_for_status()

            total_size = int(response.headers.get("content-length", 0))
            downloaded = 0

            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    temp_file.write(chunk)
                    downloaded += len(chunk)

                    if total_size > 0:
                        progress = 5 + int((downloaded / total_size) * 5)
                        await send_callback(
                            job_id,
                            "processing",
                            progress,
                            f"ë‹¤ìš´ë¡œë“œ ì¤‘... ({downloaded}/{total_size} bytes)",
                            callback_base_url=callback_base_url,
                        )

            logger.info(f"HTTP ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {temp_file.name}")
            return temp_file.name

    except Exception as e:
        logger.error(f"ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ/íŒŒì¼ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        raise Exception(f"Failed to access video: {str(e)}")


def get_default_acoustic_features() -> Dict[str, Any]:
    """ê¸°ë³¸ ìŒí–¥ íŠ¹ì„± ë°˜í™˜"""
    return {
        "volume_db": -20.0,
        "pitch_hz": 150.0,
        "spectral_centroid": 1500.0,
        "zero_crossing_rate": 0.1,
        "pitch_mean": 150.0,
        "pitch_std": 20.0,
        "mfcc_mean": [0.0] * 13,
    }


def extract_acoustic_features(audio_path: Path, segments: list) -> list[Dict[str, Any]]:
    """Extract acoustic features for segments"""
    acoustic_features_list = []

    try:
        from src.services.acoustic_analyzer import FastAcousticAnalyzer

        analyzer = FastAcousticAnalyzer(sample_rate=16000)

        for seg in segments:
            features = analyzer.extract_features(
                audio_path,
                seg.get("start", 0.0),
                seg.get("end", 0.0),
            )

            acoustic_features_list.append(
                {
                    "volume_db": features.rms_db,
                    "pitch_hz": features.pitch_mean,
                    "spectral_centroid": features.spectral_centroid,
                    "zero_crossing_rate": features.zcr,
                    "pitch_mean": features.pitch_mean,
                    "pitch_std": (
                        features.pitch_variance**0.5
                        if features.pitch_variance > 0
                        else 0.0
                    ),
                    "mfcc_mean": (
                        features.mfcc
                        if hasattr(features, "mfcc") and features.mfcc
                        else [0.0] * 13
                    ),
                }
            )

        logger.info(f"ìŒí–¥ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: {len(acoustic_features_list)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

    except Exception as e:
        logger.warning(f"ìŒí–¥ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        # Return default features for all segments
        acoustic_features_list = [get_default_acoustic_features() for _ in segments]

    return acoustic_features_list


def process_whisperx_segments(
    whisperx_result: Optional[Dict], audio_path: Optional[Path] = None
) -> tuple[list, dict]:
    """WhisperX ê²°ê³¼ë¥¼ í†µí•© ì²˜ë¦¬"""
    if not whisperx_result or "segments" not in whisperx_result:
        logger.warning("WhisperX ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return [], {}

    segments = whisperx_result["segments"]

    # DEBUG: ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ êµ¬ì¡° ë¡œê¹…
    if segments:
        first_segment = segments[0]
        logger.debug(f"ğŸ” DEBUG: ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ í‚¤ë“¤: {list(first_segment.keys())}")
        logger.debug(f"ğŸ” DEBUG: ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ ë‚´ìš©: {first_segment}")
        if "words" in first_segment and first_segment["words"]:
            first_word = first_segment["words"][0]
            logger.debug(f"ğŸ” DEBUG: ì²« ë²ˆì§¸ ë‹¨ì–´ í‚¤ë“¤: {list(first_word.keys())}")
            logger.debug(f"ğŸ” DEBUG: ì²« ë²ˆì§¸ ë‹¨ì–´ ë‚´ìš©: {first_word}")

    # ìŒí–¥ íŠ¹ì„± ì¶”ì¶œ
    acoustic_features_list = []
    if audio_path and audio_path.exists():
        acoustic_features_list = extract_acoustic_features(audio_path, segments)
    else:
        acoustic_features_list = [get_default_acoustic_features() for _ in segments]

    # ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
    processed_segments = []
    speakers_stats = {}

    for i, seg in enumerate(segments):
        speaker_id = seg.get("speaker", "SPEAKER_00")

        # Update speaker stats
        if speaker_id not in speakers_stats:
            speakers_stats[speaker_id] = {
                "total_duration": 0.0,
                "segment_count": 0,
            }

        duration = seg.get("end", 0.0) - seg.get("start", 0.0)
        speakers_stats[speaker_id]["total_duration"] += duration
        speakers_stats[speaker_id]["segment_count"] += 1

        # Extract timing information from segment
        start_time = seg.get("start", 0.0) if "start" in seg else seg.get("start_time", 0.0)
        end_time = seg.get("end", 0.0) if "end" in seg else seg.get("end_time", 0.0)

        # ë””ë²„ê·¸ ë¡œê¹…: íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸
        logger.debug(f"ğŸ” ì„¸ê·¸ë¨¼íŠ¸ {i}: start={start_time}, end={end_time}, keys={list(seg.keys())}")

        # Build segment data
        segment_data = {
            "start_time": start_time,
            "end_time": end_time,
            "duration": end_time - start_time if end_time > start_time else 0.0,
            "speaker_id": speaker_id,
            "acoustic_features": (
                acoustic_features_list[i]
                if i < len(acoustic_features_list)
                else get_default_acoustic_features()
            ),
            "text": seg.get("text", "").strip(),
            "words": [],
        }

        # Process words if available
        if "words" in seg:
            for word_idx, word in enumerate(seg["words"]):
                # Extract timing information from word
                word_start = word.get("start", 0.0) if "start" in word else word.get("start_time", 0.0)
                word_end = word.get("end", 0.0) if "end" in word else word.get("end_time", 0.0)

                # ë””ë²„ê·¸ ë¡œê¹…: ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸
                logger.debug(f"ğŸ” ë‹¨ì–´ {word_idx}: start={word_start}, end={word_end}, keys={list(word.keys())}")

                word_data = {
                    "word": word.get("word", ""),
                    "start_time": word_start,
                    "end_time": word_end,
                    "duration": word_end - word_start if word_end > word_start else 0.0,
                    "acoustic_features": {
                        "volume_db": -20.0,
                        "pitch_hz": 150.0,
                        "spectral_centroid": 1500.0,
                    },
                }
                segment_data["words"].append(word_data)

        processed_segments.append(segment_data)

    # íƒ€ì„ìŠ¤íƒ¬í”„ ê²€ì¦ ë° í†µê³„
    validate_timestamps(processed_segments)

    return processed_segments, speakers_stats


def validate_timestamps(segments: list) -> None:
    """íƒ€ì„ìŠ¤íƒ¬í”„ ê²€ì¦ ë° í†µê³„ ì¶œë ¥"""
    total_segments = len(segments)
    zero_timestamp_segments = 0
    valid_timestamp_segments = 0

    for i, segment in enumerate(segments):
        start_time = segment.get("start_time", 0.0)
        end_time = segment.get("end_time", 0.0)

        if start_time == 0.0 and end_time == 0.0:
            zero_timestamp_segments += 1
        elif start_time < end_time:
            valid_timestamp_segments += 1

        # ì²« 3ê°œì™€ ë§ˆì§€ë§‰ 3ê°œ ì„¸ê·¸ë¨¼íŠ¸ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ë¡œê¹…
        if i < 3 or i >= total_segments - 3:
            logger.info(f"âœ… ì„¸ê·¸ë¨¼íŠ¸ {i}: {start_time:.2f}s - {end_time:.2f}s | '{segment.get('text', '')[:50]}...'")

    logger.info(f"ğŸ“Š íƒ€ì„ìŠ¤íƒ¬í”„ í†µê³„: ì „ì²´={total_segments}, ìœ íš¨={valid_timestamp_segments}, 0ê°’={zero_timestamp_segments}")

    if zero_timestamp_segments > 0:
        logger.warning(f"âš ï¸ {zero_timestamp_segments}/{total_segments} ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ 0ì…ë‹ˆë‹¤!")
    else:
        logger.info("âœ… ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ìœ íš¨í•©ë‹ˆë‹¤!")


async def process_audio_core(file_path: str, language: str = "en") -> Dict[str, Any]:
    import time
    start_time = time.time()

    # ì–¸ì–´ ìµœì í™” ëª¨ë“œ ê²°ì •
    processing_mode = "targeted" if language != "auto" else "auto-detect"
    logger.info(f"ğŸ¯ ì²˜ë¦¬ ëª¨ë“œ: {processing_mode} (ì–¸ì–´: {language})")

    # Pipeline ì‹¤í–‰
    file_path_obj = Path(file_path)

    # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬ ë°©ì‹ ê²°ì •
    is_audio_file = file_path_obj.suffix.lower() in [
        ".wav",
        ".mp3",
        ".flac",
        ".aac",
        ".m4a",
    ]
    if is_audio_file:
        logger.info("ğŸ“„ ì˜¤ë””ì˜¤ íŒŒì¼ ì§ì ‘ ì²˜ë¦¬")
    else:
        logger.info("ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ í›„ ì²˜ë¦¬")

    pipeline = create_pipeline(language=language)

    result = await pipeline.process_single(
        source=file_path_obj,
        output_path=None,
    )
    # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
    processing_time = time.time() - start_time

    # WhisperX ê²°ê³¼ ì¶”ì¶œ
    whisperx_result = None
    detected_language = language  # ê¸°ë³¸ê°’
    if hasattr(pipeline, "_last_whisperx_result"):
        whisperx_result = pipeline._last_whisperx_result

        # ì‹¤ì œ ê°ì§€ëœ ì–¸ì–´ ì •ë³´ ì¶”ì¶œ
        if whisperx_result and "language" in whisperx_result:
            detected_language = whisperx_result["language"]
    # ì˜¤ë””ì˜¤ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    audio_path = None
    if hasattr(pipeline, "_last_audio_path") and pipeline._last_audio_path:
        audio_path = Path(pipeline._last_audio_path)

    # ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
    processed_segments, speakers_stats = process_whisperx_segments(
        whisperx_result, audio_path
    )
    logger.info(
        f"âœ… ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: {len(processed_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, {len(speakers_stats)}ëª… í™”ì"
    )

    # ë©”íƒ€ë°ì´í„° ìƒì„± (ì–¸ì–´ ìµœì í™” ì •ë³´ í¬í•¨)
    metadata = {
        "filename": Path(file_path).name,
        "duration": result.metadata.duration if result.metadata else 0,
        "total_segments": len(processed_segments),
        "unique_speakers": len(speakers_stats),
        "processing_time": processing_time,
        "language_requested": language,
        "language_detected": detected_language,
        "processing_mode": processing_mode,
    }

    return {
        "metadata": metadata,
        "segments": processed_segments,
        "speakers": speakers_stats,
        "whisperx_result": whisperx_result,
    }


# ========== API Endpoints ==========


@app.post("/api/upload-video/process-video", response_model=ProcessVideoResponse)
async def process_video_api(
    request: ProcessVideoRequest, background_tasks: BackgroundTasks
):
    """Backend í˜¸í™˜ ë¹„ë””ì˜¤ ì²˜ë¦¬ API"""
    try:
        job_id = request.job_id

        # Job ìƒíƒœ ì¶”ì 
        jobs[job_id] = {
            "status": "accepted",
            "video_url": request.video_url,
            "started_at": datetime.now().isoformat(),
        }

        logger.info(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ìš”ì²­ ì ‘ìˆ˜ - job_id: {job_id}")

        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘ (ì¶”ê°€ íŒŒë¼ë¯¸í„°ì™€ í•¨ê»˜)
        background_tasks.add_task(
            process_video_with_callback,
            job_id,
            request.video_url,
            request.fastapi_base_url,
            request.language,
        )

        return ProcessVideoResponse(
            job_id=job_id,
            status="processing",  # "accepted" â†’ "processing"ìœ¼ë¡œ ë³€ê²½
            message="ë¹„ë””ì˜¤ ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
            status_url=f"/api/upload-video/status/{job_id}",  # ì¶”ê°€
            estimated_time=300,
        )

    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ìš”ì²­ ì‹¤íŒ¨ - job_id: {request.job_id}, error: {str(e)}")
        await send_callback(
            request.job_id,
            "failed",
            0,
            error_message=str(e),
            error_code="INVALID_REQUEST",
            callback_base_url=request.fastapi_base_url,
        )
        raise HTTPException(
            status_code=400,
            detail={
                "error": {
                    "code": "INVALID_REQUEST",
                    "message": str(e),
                    "job_id": request.job_id,
                }
            },
        )


async def process_video_with_callback(
    job_id: str,
    video_url: str,
    callback_base_url: Optional[str] = None,
    language: str = "en",
):
    """API ëª…ì„¸ì— ë”°ë¥¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ì½œë°±"""
    start_time = datetime.now()
    video_path = None

    try:
        # Progress milestones
        milestones = [
            (10, "ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ"),
            (25, "ìŒì„± êµ¬ê°„ ê°ì§€ ì¤‘..."),
            (40, "í™”ì ì‹ë³„ ì¤‘..."),
            (60, "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."),
            (75, "ê°ì • ë¶„ì„ ì¤‘..."),
            (90, "ê²°ê³¼ ì •ë¦¬ ì¤‘..."),
        ]

        # 1. ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        logger.info(f"ì‘ì—… ì‹œì‘: {job_id}")
        video_path = await download_from_url(video_url, job_id, callback_base_url)
        await send_callback(
            job_id,
            "processing",
            milestones[0][0],
            milestones[0][1],
            callback_base_url=callback_base_url,
        )
        logger.info("ë¹„ë””ì˜¤ ì¤€ë¹„ ì™„ë£Œ, ML ì²˜ë¦¬ ì‹œì‘")

        # 2-5. Pipeline ì²˜ë¦¬ (ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸)
        for progress, message in milestones[1:4]:
            await send_callback(
                job_id,
                "processing",
                progress,
                message,
                callback_base_url=callback_base_url,
            )

        # ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤í–‰
        logger.info("ML íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
        result = await process_audio_core(video_path, language=language)
        logger.info("ML íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ")

        # 6. ê°ì • ë¶„ì„
        await send_callback(
            job_id,
            "processing",
            milestones[4][0],
            milestones[4][1],
            callback_base_url=callback_base_url,
        )

        # 7. ê²°ê³¼ ì •ë¦¬
        await send_callback(
            job_id,
            "processing",
            milestones[5][0],
            milestones[5][1],
            callback_base_url=callback_base_url,
        )

        # API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë°±ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹)
        segments_for_api = []
        word_segments = []  # ë‹¨ì–´ ë‹¨ìœ„ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€

        for seg in result["segments"]:
            segment_data = {
                "start_time": seg["start_time"],
                "end_time": seg["end_time"],
                "speaker": {"speaker_id": seg["speaker_id"]},
                "text": seg["text"],
                "words": [
                    {
                        "word": w["word"],
                        "start": w["start_time"],
                        "end": w["end_time"],
                        "acoustic_features": {  # ì¤‘ì²© ê°ì²´ë¡œ ë³€ê²½
                            "volume_db": w["acoustic_features"]["volume_db"],
                            "pitch_hz": w["acoustic_features"]["pitch_hz"],
                            "spectral_centroid": w["acoustic_features"].get("spectral_centroid", 1500.0)
                        }
                    }
                    for w in seg.get("words", [])
                ],
            }
            segments_for_api.append(segment_data)

            # word_segments ìƒì„±
            for word in seg.get("words", []):
                word_segments.append({
                    "word": word["word"],
                    "start_time": word["start_time"],
                    "end_time": word["end_time"],
                    "speaker_id": seg["speaker_id"],
                    "confidence": 0.95
                })

        processing_time = (datetime.now() - start_time).total_seconds()

        # ë°±ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” ì˜¬ë°”ë¥¸ ê²°ê³¼ êµ¬ì¡°
        final_result = {
            "segments": segments_for_api,
            "word_segments": word_segments,  # ì¶”ê°€
            "speakers": result["speakers"],  # result ë‚´ë¶€ë¡œ ì´ë™
            "text": " ".join([seg["text"] for seg in segments_for_api]),
            "language": result["metadata"].get("language_detected", language),
            "duration": result["metadata"]["duration"],
            "metadata": {
                "model_version": "whisperx-base",
                "processing_time": processing_time,
                "unique_speakers": result["metadata"]["unique_speakers"],
                "total_segments": result["metadata"]["total_segments"],
                "language_requested": result["metadata"].get("language_requested", language),
                "language_detected": result["metadata"].get("language_detected", language),
                "processing_mode": "targeted" if language != "auto" else "auto-detect",
                "processed_at": datetime.now().isoformat()
            }
        }

        # ì™„ë£Œ ì½œë°± ì „ì†¡ (ëª¨ë“  ë°ì´í„°ëŠ” result ì•ˆì—)
        await send_callback(
            job_id,
            "completed",
            100,
            "ë¶„ì„ ì™„ë£Œ",
            result=final_result,
            callback_base_url=callback_base_url,
        )

        logger.info(
            f"âœ… ë¶„ì„ ì™„ë£Œ - job_id: {job_id}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ"
        )

        # Job ìƒíƒœ ì—…ë°ì´íŠ¸
        jobs[job_id] = {
            "status": "completed",
            "processing_time": processing_time,
            "completed_at": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨ - job_id: {job_id}, error: {str(e)}")

        error_code = (
            "DOWNLOAD_ERROR" if "download" in str(e).lower() else "PROCESSING_ERROR"
        )
        await send_callback(
            job_id,
            "failed",
            0,
            error_message=str(e),
            error_code=error_code,
            callback_base_url=callback_base_url,
        )

        jobs[job_id] = {
            "status": "failed",
            "error": str(e),
            "failed_at": datetime.now().isoformat(),
        }

    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë§Œ)
        if video_path and Path(video_path).exists() and "/tmp" in video_path:
            try:
                Path(video_path).unlink()
                logger.info(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬: {video_path}")
            except:
                pass


@app.post("/transcribe")
async def transcribe(request: TranscribeRequest):
    """ë°±ì—”ë“œ í˜¸í™˜ ë™ê¸° ì „ì‚¬ API"""
    start_time = datetime.now()

    try:
        logger.info(f"ì „ì‚¬ ìš”ì²­ ì‹œì‘ - video_path: {request.video_path}")

        # ê°€ìƒì˜ job_id ìƒì„± (ì§„í–‰ìƒí™© ì¶”ì ìš©)
        job_id = str(uuid.uuid4())

        # Progress milestones (ì˜¤ë””ì˜¤ ìš°ì„  ì²˜ë¦¬)
        if request.audio_path:
            progress_steps = [
                (5, "ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì¤‘..."),
                (20, "ìŒì„± êµ¬ê°„ ë¶„ì„ ì¤‘..."),
                (65, "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."),
                (95, "ê°ì • ë¶„ì„ ì¤‘..."),
                (100, "ë¶„ì„ ì™„ë£Œ"),
            ]
        else:
            # í•˜ìœ„ í˜¸í™˜ì„±: ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œì´ í•„ìš”í•œ ê²½ìš°
            progress_steps = [
                (5, "ë¹„ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì¤‘..."),
                (15, "ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘..."),
                (25, "ìŒì„± êµ¬ê°„ ë¶„ì„ ì¤‘..."),
                (65, "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."),
                (95, "ê°ì • ë¶„ì„ ì¤‘..."),
                (100, "ë¶„ì„ ì™„ë£Œ"),
            ]

        # ì²« ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
        await send_callback(
            job_id, "processing", progress_steps[0][0], progress_steps[0][1]
        )

        # ì˜¤ë””ì˜¤ íŒŒì¼ ì¤€ë¹„ (ì˜¤ë””ì˜¤ ìš°ì„ , ë¹„ë””ì˜¤ëŠ” fallback)
        audio_s3_path = request.audio_path or request.video_path  # í•˜ìœ„ í˜¸í™˜ì„±
        file_extension = (
            ".wav" if request.audio_path else ".mp4"
        )  # ì˜¤ë””ì˜¤ë©´ .wav, ë¹„ë””ì˜¤ë©´ .mp4

        with tempfile.NamedTemporaryFile(
            suffix=file_extension, delete=False
        ) as temp_file:
            try:
                # S3ì—ì„œ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œë„
                s3_client.download_file(S3_BUCKET, audio_s3_path, temp_file.name)
                if request.audio_path:
                    logger.info(f"S3ì—ì„œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {request.audio_path}")
                else:
                    logger.info(
                        f"S3ì—ì„œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (ì˜¤ë””ì˜¤ ì¶”ì¶œ í•„ìš”): {request.video_path}"
                    )
                actual_file_path = temp_file.name
            except Exception as s3_error:
                logger.warning(f"S3 ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, ë¡œì»¬ ê²½ë¡œ ì‚¬ìš©: {s3_error}")
                actual_file_path = audio_s3_path

            # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ (ì²« ë²ˆì§¸ ë‹¨ê³„ ì´í›„ ë¶„ì„ ì „ê¹Œì§€)
            analysis_start_index = (
                2 if request.audio_path else 3
            )  # ì˜¤ë””ì˜¤ëŠ” 2ë‹¨ê³„ë¶€í„°, ë¹„ë””ì˜¤ëŠ” 3ë‹¨ê³„ë¶€í„°
            for progress, message in progress_steps[1:analysis_start_index]:
                await send_callback(job_id, "processing", progress, message)

            try:
                # ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤í–‰
                result = await process_audio_core(
                    actual_file_path, language=request.language
                )

                # ê°ì • ë¶„ì„ ì§„í–‰ìƒí™©
                await send_callback(
                    job_id, "processing", progress_steps[4][0], progress_steps[4][1]
                )

                processing_time = (datetime.now() - start_time).total_seconds()

                # ê°„ì†Œí™”ëœ ê²°ê³¼ ìƒì„±
                detailed_result = {
                    "success": True,
                    "segments": result["segments"],
                    "speakers": result["speakers"],
                    "metadata": {
                        **result["metadata"],
                        "processing_time": processing_time,
                        "processed_at": datetime.now().isoformat(),
                    },
                    "processing_time": processing_time,
                    "error": None,
                    "error_code": None,
                }

                # ì™„ë£Œ ì§„í–‰ìƒí™©
                await send_callback(
                    job_id, "processing", progress_steps[5][0], progress_steps[5][1]
                )

                logger.info(f"ì „ì‚¬ ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
                logger.info(f"ë°˜í™˜í•  ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(detailed_result['segments'])}")

                return detailed_result

            except Exception as analysis_error:
                logger.error(f"ë¶„ì„ ì‹¤íŒ¨: {analysis_error}")
                processing_time = (datetime.now() - start_time).total_seconds()

                return {
                    "success": False,
                    "error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(analysis_error)}",
                    "error_code": "ANALYSIS_ERROR",
                    "processing_time": processing_time,
                }

    except Exception as e:
        processing_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"ì „ì‚¬ ìš”ì²­ ì‹¤íŒ¨ - Error: {str(e)}")

        return {
            "success": False,
            "error": f"ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
            "error_code": "REQUEST_ERROR",
            "processing_time": processing_time,
        }


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}


@app.get("/jobs/{job_id}")
async def get_job_status(job_id: str):
    """Get job status"""
    if job_id not in jobs:
        raise HTTPException(status_code=404, detail="Job not found")
    return jobs[job_id]


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ECG Audio Analyzer ML API Server")
    parser.add_argument("--host", default="0.0.0.0", help="ë°”ì¸ë“œ í˜¸ìŠ¤íŠ¸")
    parser.add_argument("--port", type=int, default=8080, help="ë°”ì¸ë“œ í¬íŠ¸")
    parser.add_argument("--workers", type=int, default=1, help="ì›Œì»¤ ìˆ˜")
    parser.add_argument(
        "--log-level", default="info", choices=["debug", "info", "warning", "error"]
    )

    args = parser.parse_args()

    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=getattr(logging, args.log_level.upper()),
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    logger.info("ğŸš€ ECG Audio Analyzer ML API ì„œë²„ ì‹œì‘")
    logger.info(f"   í˜¸ìŠ¤íŠ¸: {args.host}:{args.port}")
    logger.info(f"   ì›Œì»¤ ìˆ˜: {args.workers}")
    logger.info(f"   ë¡œê·¸ ë ˆë²¨: {args.log_level}")
    logger.info(f"   ë°±ì—”ë“œ URL: {BACKEND_URL if BACKEND_URL else 'Not configured'}")
    logger.info(f"   ì½œë°± í™œì„±í™”: {ENABLE_CALLBACKS}")

    # GPU í™•ì¸
    try:
        import torch

        if torch.cuda.is_available():
            logger.info(f"   GPU: {torch.cuda.device_count()}ê°œ ì‚¬ìš© ê°€ëŠ¥")
            for i in range(torch.cuda.device_count()):
                logger.info(f"     - GPU {i}: {torch.cuda.get_device_name(i)}")
        else:
            logger.warning("   GPU: ì‚¬ìš© ë¶ˆê°€ (CPU ëª¨ë“œ)")
    except ImportError:
        logger.warning("   PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")

    # FastAPI ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        app,
        host=args.host,
        port=args.port,
        workers=args.workers,
        access_log=True,
        log_level=args.log_level,
    )
