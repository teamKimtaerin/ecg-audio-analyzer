import sys
from pathlib import Path
import logging
import os
import warnings
from typing import Dict, Any, Optional
from datetime import datetime
import tempfile
import uuid

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Suppress warnings
warnings.filterwarnings("ignore", category=UserWarning)

from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
import uvicorn
import requests
import boto3

from src.utils.logger import get_logger
from src.pipeline.manager import PipelineManager
from config.base_settings import BaseConfig, ProcessingConfig

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="ECG Model Server",
    description="EC2 ML ì„œë²„ - ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ë¶„ì„ API",
    version="1.0.0",
)

# AWS S3 ë° Backend ì„¤ì •
s3_client = boto3.client("s3")
S3_BUCKET = os.getenv("S3_BUCKET", "ecg-project-pipeline-dev-video-storage-np9div7")
BACKEND_URL = os.getenv("BACKEND_URL", os.getenv("ECG_BACKEND_URL", None))
ENABLE_CALLBACKS = bool(BACKEND_URL and BACKEND_URL.strip())

# In-memory job tracking
jobs = {}

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)


# ========== Pydantic Models ==========


class ProcessVideoRequest(BaseModel):
    """Backend í˜¸í™˜ ë¹„ë””ì˜¤ ì²˜ë¦¬ ìš”ì²­"""

    job_id: str
    video_url: str
    # ë°±ì—”ë“œì—ì„œ ë³´ë‚´ëŠ” ì¶”ê°€ í•„ë“œë“¤
    fastapi_base_url: Optional[str] = None  # ë™ì  ì½œë°± URL
    enable_gpu: bool = True
    emotion_detection: bool = True
    language: str = "auto"
    max_workers: int = 4


class ProcessVideoResponse(BaseModel):
    """Backend í˜¸í™˜ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‘ë‹µ"""

    job_id: str
    status: str
    message: str
    status_url: Optional[str] = None  # ì¶”ê°€: ìƒíƒœ ì¡°íšŒ URL
    estimated_time: Optional[int] = 300


class MLProgressCallback(BaseModel):
    """ML ì§„í–‰ ìƒí™© ì½œë°±"""

    job_id: str
    status: str  # processing, completed, failed
    progress: int  # 0-100
    message: Optional[str] = None
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    error_code: Optional[str] = None


class TranscribeRequest(BaseModel):
    """ë°±ì—”ë“œ í˜¸í™˜ ì „ì‚¬ ìš”ì²­"""

    video_path: str  # Deprecated: í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
    audio_path: Optional[str] = None  # ìƒˆë¡œìš´ í•„ë“œ: S3 ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
    video_url: Optional[str] = None
    enable_gpu: bool = True
    emotion_detection: bool = True
    language: str = "en"


class BackendTranscribeResponse(BaseModel):
    """ìƒì„¸ ë¶„ì„ ì‘ë‹µ"""

    success: bool
    metadata: Optional[Dict[str, Any]] = None
    speakers: Optional[Dict[str, Any]] = None
    segments: Optional[list] = None
    processing_time: float
    error: Optional[str] = None
    error_code: Optional[str] = None


# ========== Helper Functions ==========


def create_pipeline(language: str = "en") -> PipelineManager:
    return PipelineManager(
        base_config=BaseConfig(),
        processing_config=ProcessingConfig(),
        language=language,
    )


async def send_callback(
    job_id: str,
    status: str,
    progress: int,
    message: str = "",
    result: Optional[Dict] = None,
    error_message: Optional[str] = None,
    error_code: Optional[str] = None,
    callback_base_url: Optional[str] = None,
):
    """Send progress/error callback to backend"""
    # ë™ì  ì½œë°± URL ê²°ì •
    base_url = callback_base_url or BACKEND_URL
    if not base_url or not base_url.strip():
        logger.debug(f"No callback URL configured - {status}: {message} ({progress}%)")
        return

    try:
        payload = MLProgressCallback(
            job_id=job_id,
            status=status,
            progress=progress,
            message=message or "ì²˜ë¦¬ ì¤‘...",
            result=result,
            error_message=error_message,
            error_code=error_code,
        ).model_dump()

        # ë°±ì—”ë“œ API ê²½ë¡œì— ë§ì¶° ìˆ˜ì • (ê¸°ì¡´: /api/v1/ml/ml-results)
        callback_endpoint = f"{base_url}/api/upload-video/result"

        response = requests.post(
            callback_endpoint,
            json=payload,
            headers={"Content-Type": "application/json", "User-Agent": "ML-Server/1.0"},
            timeout=30 if result else 10,
        )

        if response.status_code == 200:
            logger.info(f"Callback sent to {callback_endpoint}: {status} - {message} ({progress}%)")
        else:
            logger.warning(f"Callback failed to {callback_endpoint}: {response.status_code}")

    except Exception as e:
        logger.error(f"Callback error to {base_url}: {str(e)}")


async def download_from_url(url: str, job_id: str, callback_base_url: Optional[str] = None) -> str:
    """URLì—ì„œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ë¡œì»¬ íŒŒì¼ í™•ì¸"""
    try:
        # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ì§€ í™•ì¸
        local_path = Path(url)
        if local_path.exists():
            logger.info(f"ë¡œì»¬ íŒŒì¼ ì‚¬ìš©: {url}")
            await send_callback(job_id, "processing", 10, "ë¡œì»¬ íŒŒì¼ í™•ì¸ ì™„ë£Œ", callback_base_url=callback_base_url)
            return str(local_path.absolute())

        # URL ë‹¤ìš´ë¡œë“œ
        await send_callback(job_id, "processing", 5, "ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹œì‘...", callback_base_url=callback_base_url)

        with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as temp_file:
            response = requests.get(url, stream=True, timeout=60)
            response.raise_for_status()

            total_size = int(response.headers.get("content-length", 0))
            downloaded = 0

            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    temp_file.write(chunk)
                    downloaded += len(chunk)

                    if total_size > 0:
                        progress = 5 + int((downloaded / total_size) * 5)
                        await send_callback(
                            job_id,
                            "processing",
                            progress,
                            f"ë‹¤ìš´ë¡œë“œ ì¤‘... ({downloaded}/{total_size} bytes)",
                            callback_base_url=callback_base_url,
                        )

            logger.info(f"ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {temp_file.name}")
            return temp_file.name

    except Exception as e:
        logger.error(f"ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ/íŒŒì¼ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        raise Exception(f"Failed to access video: {str(e)}")


def get_default_acoustic_features() -> Dict[str, Any]:
    """ê¸°ë³¸ ìŒí–¥ íŠ¹ì„± ë°˜í™˜"""
    return {
        "volume_db": -20.0,
        "pitch_hz": 150.0,
        "spectral_centroid": 1500.0,
        "zero_crossing_rate": 0.1,
        "pitch_mean": 150.0,
        "pitch_std": 20.0,
        "mfcc_mean": [0.0] * 13,
    }


def extract_acoustic_features(audio_path: Path, segments: list) -> list[Dict[str, Any]]:
    """Extract acoustic features for segments"""
    acoustic_features_list = []

    try:
        from src.services.acoustic_analyzer import FastAcousticAnalyzer

        analyzer = FastAcousticAnalyzer(sample_rate=16000)

        for seg in segments:
            features = analyzer.extract_features(
                audio_path,
                seg.get("start", 0.0),
                seg.get("end", 0.0),
            )

            acoustic_features_list.append(
                {
                    "volume_db": features.rms_db,
                    "pitch_hz": features.pitch_mean,
                    "spectral_centroid": features.spectral_centroid,
                    "zero_crossing_rate": features.zcr,
                    "pitch_mean": features.pitch_mean,
                    "pitch_std": (
                        features.pitch_variance**0.5
                        if features.pitch_variance > 0
                        else 0.0
                    ),
                    "mfcc_mean": (
                        features.mfcc
                        if hasattr(features, "mfcc") and features.mfcc
                        else [0.0] * 13
                    ),
                }
            )

        logger.info(f"ìŒí–¥ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: {len(acoustic_features_list)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

    except Exception as e:
        logger.warning(f"ìŒí–¥ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        # Return default features for all segments
        acoustic_features_list = [get_default_acoustic_features() for _ in segments]

    return acoustic_features_list


def process_whisperx_segments(
    whisperx_result: Optional[Dict], audio_path: Optional[Path] = None
) -> tuple[list, dict]:
    """WhisperX ê²°ê³¼ë¥¼ í†µí•© ì²˜ë¦¬"""
    if not whisperx_result or "segments" not in whisperx_result:
        logger.warning("WhisperX ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return [], {}

    segments = whisperx_result["segments"]

    # ìŒí–¥ íŠ¹ì„± ì¶”ì¶œ
    acoustic_features_list = []
    if audio_path and audio_path.exists():
        acoustic_features_list = extract_acoustic_features(audio_path, segments)
    else:
        acoustic_features_list = [get_default_acoustic_features() for _ in segments]

    # ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
    processed_segments = []
    speakers_stats = {}

    for i, seg in enumerate(segments):
        speaker_id = seg.get("speaker", "SPEAKER_00")

        # Update speaker stats
        if speaker_id not in speakers_stats:
            speakers_stats[speaker_id] = {
                "total_duration": 0.0,
                "segment_count": 0,
            }

        duration = seg.get("end", 0.0) - seg.get("start", 0.0)
        speakers_stats[speaker_id]["total_duration"] += duration
        speakers_stats[speaker_id]["segment_count"] += 1

        # Build segment data
        segment_data = {
            "start_time": seg.get("start", 0.0),
            "end_time": seg.get("end", 0.0),
            "duration": duration,
            "speaker_id": speaker_id,
            "acoustic_features": (
                acoustic_features_list[i]
                if i < len(acoustic_features_list)
                else get_default_acoustic_features()
            ),
            "text": seg.get("text", "").strip(),
            "words": [],
        }

        # Process words if available
        if "words" in seg:
            for word in seg["words"]:
                word_data = {
                    "word": word.get("word", ""),
                    "start_time": word.get("start", 0.0),
                    "end_time": word.get("end", 0.0),
                    "duration": word.get("end", 0.0) - word.get("start", 0.0),
                    "acoustic_features": {
                        "volume_db": -20.0,
                        "pitch_hz": 150.0,
                        "spectral_centroid": 1500.0,
                    },
                }
                segment_data["words"].append(word_data)

        processed_segments.append(segment_data)

    return processed_segments, speakers_stats


async def process_audio_core(file_path: str, language: str = "en") -> Dict[str, Any]:
    """ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì²˜ë¦¬ í•µì‹¬ ë¡œì§ (ì˜¤ë””ì˜¤ ìš°ì„ )"""
    # Pipeline ì‹¤í–‰
    file_path_obj = Path(file_path)
    logger.info(f"Pipeline ì²˜ë¦¬ ì‹œì‘: {file_path_obj.name}")

    # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬ ë°©ì‹ ê²°ì •
    is_audio_file = file_path_obj.suffix.lower() in [
        ".wav",
        ".mp3",
        ".flac",
        ".aac",
        ".m4a",
    ]
    if is_audio_file:
        logger.info("ì˜¤ë””ì˜¤ íŒŒì¼ ì§ì ‘ ì²˜ë¦¬")
    else:
        logger.info("ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ í›„ ì²˜ë¦¬")

    pipeline = create_pipeline(language=language)

    result = await pipeline.process_single(
        source=file_path_obj,
        output_path=None,
    )
    logger.info("Pipeline ì²˜ë¦¬ ì™„ë£Œ")

    # WhisperX ê²°ê³¼ ì¶”ì¶œ
    whisperx_result = None
    if hasattr(pipeline, "_last_whisperx_result"):
        whisperx_result = pipeline._last_whisperx_result

    # ì˜¤ë””ì˜¤ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    audio_path = None
    if hasattr(pipeline, "_last_audio_path") and pipeline._last_audio_path:
        audio_path = Path(pipeline._last_audio_path)
    # NOTE: ì˜¤ë””ì˜¤ íŒŒì¼ ì§ì ‘ ì²˜ë¦¬ ì‹œ AudioCleaner ì‚¬ìš© ì•ˆ í•¨ (Backendì—ì„œ ì´ë¯¸ ì˜¤ë””ì˜¤ ì¶”ì¶œ)
    # elif file_path.endswith(".mp4"):
    #     try:
    #         cleaner = AudioCleaner(target_sr=16000)
    #         audio_result = cleaner.process(file_path, output_path="temp")
    #         if isinstance(audio_result, str):
    #             audio_path = Path(audio_result)
    #             logger.info(f"AudioCleanerë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ: {audio_path}")
    #     except Exception as e:
    #         logger.error(f"AudioCleaner ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    # ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
    logger.info("WhisperX ê²°ê³¼ ì²˜ë¦¬ ì‹œì‘")
    processed_segments, speakers_stats = process_whisperx_segments(
        whisperx_result, audio_path
    )
    logger.info(
        f"ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: {len(processed_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, {len(speakers_stats)}ëª… í™”ì"
    )

    # ë©”íƒ€ë°ì´í„° ìƒì„±
    metadata = {
        "filename": Path(file_path).name,
        "duration": result.metadata.duration if result.metadata else 0,
        "total_segments": len(processed_segments),
        "unique_speakers": len(speakers_stats),
    }

    return {
        "metadata": metadata,
        "segments": processed_segments,
        "speakers": speakers_stats,
        "whisperx_result": whisperx_result,
    }


# ========== API Endpoints ==========


@app.post("/api/upload-video/process-video", response_model=ProcessVideoResponse)
async def process_video_api(
    request: ProcessVideoRequest, background_tasks: BackgroundTasks
):
    """Backend í˜¸í™˜ ë¹„ë””ì˜¤ ì²˜ë¦¬ API"""
    try:
        job_id = request.job_id

        # Job ìƒíƒœ ì¶”ì 
        jobs[job_id] = {
            "status": "accepted",
            "video_url": request.video_url,
            "started_at": datetime.now().isoformat(),
        }

        logger.info(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ìš”ì²­ ì ‘ìˆ˜ - job_id: {job_id}")

        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘ (ì¶”ê°€ íŒŒë¼ë¯¸í„°ì™€ í•¨ê»˜)
        background_tasks.add_task(
            process_video_with_callback, 
            job_id, 
            request.video_url,
            request.fastapi_base_url,
            request.language
        )

        return ProcessVideoResponse(
            job_id=job_id,
            status="processing",  # "accepted" â†’ "processing"ìœ¼ë¡œ ë³€ê²½
            message="ë¹„ë””ì˜¤ ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
            status_url=f"/api/upload-video/status/{job_id}",  # ì¶”ê°€
            estimated_time=300,
        )

    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ìš”ì²­ ì‹¤íŒ¨ - job_id: {request.job_id}, error: {str(e)}")
        await send_callback(
            request.job_id,
            "failed",
            0,
            error_message=str(e),
            error_code="INVALID_REQUEST",
            callback_base_url=request.fastapi_base_url,
        )
        raise HTTPException(
            status_code=400,
            detail={
                "error": {
                    "code": "INVALID_REQUEST",
                    "message": str(e),
                    "job_id": request.job_id,
                }
            },
        )


async def process_video_with_callback(
    job_id: str, 
    video_url: str,
    callback_base_url: Optional[str] = None,
    language: str = "en"
):
    """API ëª…ì„¸ì— ë”°ë¥¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ì½œë°±"""
    start_time = datetime.now()
    video_path = None

    try:
        # Progress milestones
        milestones = [
            (10, "ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ"),
            (25, "ìŒì„± êµ¬ê°„ ê°ì§€ ì¤‘..."),
            (40, "í™”ì ì‹ë³„ ì¤‘..."),
            (60, "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."),
            (75, "ê°ì • ë¶„ì„ ì¤‘..."),
            (90, "ê²°ê³¼ ì •ë¦¬ ì¤‘..."),
        ]

        # 1. ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        logger.info(f"ì‘ì—… ì‹œì‘: {job_id}")
        video_path = await download_from_url(video_url, job_id, callback_base_url)
        await send_callback(job_id, "processing", milestones[0][0], milestones[0][1], callback_base_url=callback_base_url)
        logger.info("ë¹„ë””ì˜¤ ì¤€ë¹„ ì™„ë£Œ, ML ì²˜ë¦¬ ì‹œì‘")

        # 2-5. Pipeline ì²˜ë¦¬ (ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸)
        for progress, message in milestones[1:4]:
            await send_callback(job_id, "processing", progress, message, callback_base_url=callback_base_url)

        # ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤í–‰
        logger.info("ML íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
        result = await process_audio_core(video_path, language=language)
        logger.info("ML íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ")

        # 6. ê°ì • ë¶„ì„
        await send_callback(job_id, "processing", milestones[4][0], milestones[4][1], callback_base_url=callback_base_url)

        # 7. ê²°ê³¼ ì •ë¦¬
        await send_callback(job_id, "processing", milestones[5][0], milestones[5][1], callback_base_url=callback_base_url)

        # API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë°±ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹)
        segments_for_api = []
        for seg in result["segments"]:
            segment_data = {
                "start_time": seg["start_time"],
                "end_time": seg["end_time"],
                "speaker": {"speaker_id": seg["speaker_id"]},
                "text": seg["text"],
                "words": [
                    {
                        "word": w["word"],
                        "start": w["start_time"],
                        "end": w["end_time"],
                        "volume_db": w["acoustic_features"]["volume_db"],
                        "pitch_hz": w["acoustic_features"]["pitch_hz"],
                    }
                    for w in seg.get("words", [])
                ],
            }
            segments_for_api.append(segment_data)

        processing_time = (datetime.now() - start_time).total_seconds()

        # ë°±ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” ê²°ê³¼ êµ¬ì¡°ë¡œ ë³€í™˜
        final_result = {
            "text": " ".join([seg["text"] for seg in segments_for_api]),  # ì „ì²´ í…ìŠ¤íŠ¸
            "segments": segments_for_api,
            "language": language,
            "duration": result["metadata"]["duration"],
            "metadata": {
                "model_version": "whisperx-base",
                "processing_time": processing_time,
                "unique_speakers": result["metadata"]["unique_speakers"],
                "total_segments": result["metadata"]["total_segments"]
            }
        }

        # ì™„ë£Œ ì½œë°± ì „ì†¡
        await send_callback(job_id, "completed", 100, "ë¶„ì„ ì™„ë£Œ", result=final_result, callback_base_url=callback_base_url)

        logger.info(
            f"âœ… ë¶„ì„ ì™„ë£Œ - job_id: {job_id}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ"
        )

        # Job ìƒíƒœ ì—…ë°ì´íŠ¸
        jobs[job_id] = {
            "status": "completed",
            "processing_time": processing_time,
            "completed_at": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨ - job_id: {job_id}, error: {str(e)}")

        error_code = (
            "DOWNLOAD_ERROR" if "download" in str(e).lower() else "PROCESSING_ERROR"
        )
        await send_callback(
            job_id, "failed", 0, error_message=str(e), error_code=error_code, callback_base_url=callback_base_url
        )

        jobs[job_id] = {
            "status": "failed",
            "error": str(e),
            "failed_at": datetime.now().isoformat(),
        }

    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë§Œ)
        if video_path and Path(video_path).exists() and "/tmp" in video_path:
            try:
                Path(video_path).unlink()
                logger.info(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬: {video_path}")
            except:
                pass


@app.post("/transcribe")
async def transcribe(request: TranscribeRequest):
    """ë°±ì—”ë“œ í˜¸í™˜ ë™ê¸° ì „ì‚¬ API"""
    start_time = datetime.now()

    try:
        logger.info(f"ì „ì‚¬ ìš”ì²­ ì‹œì‘ - video_path: {request.video_path}")

        # ê°€ìƒì˜ job_id ìƒì„± (ì§„í–‰ìƒí™© ì¶”ì ìš©)
        job_id = str(uuid.uuid4())

        # Progress milestones (ì˜¤ë””ì˜¤ ìš°ì„  ì²˜ë¦¬)
        if request.audio_path:
            progress_steps = [
                (5, "ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì¤‘..."),
                (20, "ìŒì„± êµ¬ê°„ ë¶„ì„ ì¤‘..."),
                (65, "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."),
                (95, "ê°ì • ë¶„ì„ ì¤‘..."),
                (100, "ë¶„ì„ ì™„ë£Œ"),
            ]
        else:
            # í•˜ìœ„ í˜¸í™˜ì„±: ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œì´ í•„ìš”í•œ ê²½ìš°
            progress_steps = [
                (5, "ë¹„ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì¤‘..."),
                (15, "ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘..."),
                (25, "ìŒì„± êµ¬ê°„ ë¶„ì„ ì¤‘..."),
                (65, "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."),
                (95, "ê°ì • ë¶„ì„ ì¤‘..."),
                (100, "ë¶„ì„ ì™„ë£Œ"),
            ]

        # ì²« ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
        await send_callback(
            job_id, "processing", progress_steps[0][0], progress_steps[0][1]
        )

        # ì˜¤ë””ì˜¤ íŒŒì¼ ì¤€ë¹„ (ì˜¤ë””ì˜¤ ìš°ì„ , ë¹„ë””ì˜¤ëŠ” fallback)
        audio_s3_path = request.audio_path or request.video_path  # í•˜ìœ„ í˜¸í™˜ì„±
        file_extension = (
            ".wav" if request.audio_path else ".mp4"
        )  # ì˜¤ë””ì˜¤ë©´ .wav, ë¹„ë””ì˜¤ë©´ .mp4

        with tempfile.NamedTemporaryFile(
            suffix=file_extension, delete=False
        ) as temp_file:
            try:
                # S3ì—ì„œ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œë„
                s3_client.download_file(S3_BUCKET, audio_s3_path, temp_file.name)
                if request.audio_path:
                    logger.info(f"S3ì—ì„œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {request.audio_path}")
                else:
                    logger.info(
                        f"S3ì—ì„œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (ì˜¤ë””ì˜¤ ì¶”ì¶œ í•„ìš”): {request.video_path}"
                    )
                actual_file_path = temp_file.name
            except Exception as s3_error:
                logger.warning(f"S3 ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, ë¡œì»¬ ê²½ë¡œ ì‚¬ìš©: {s3_error}")
                actual_file_path = audio_s3_path

            # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ (ì²« ë²ˆì§¸ ë‹¨ê³„ ì´í›„ ë¶„ì„ ì „ê¹Œì§€)
            analysis_start_index = (
                2 if request.audio_path else 3
            )  # ì˜¤ë””ì˜¤ëŠ” 2ë‹¨ê³„ë¶€í„°, ë¹„ë””ì˜¤ëŠ” 3ë‹¨ê³„ë¶€í„°
            for progress, message in progress_steps[1:analysis_start_index]:
                await send_callback(job_id, "processing", progress, message)

            try:
                # ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤í–‰
                result = await process_audio_core(
                    actual_file_path, language=request.language
                )

                # ê°ì • ë¶„ì„ ì§„í–‰ìƒí™©
                await send_callback(
                    job_id, "processing", progress_steps[4][0], progress_steps[4][1]
                )

                processing_time = (datetime.now() - start_time).total_seconds()

                # Option C í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ìƒì„± (ê°ì²´ ê¸°ë°˜ ìƒì„¸ êµ¬ì¡°)
                detailed_result = {
                    "success": True,
                    "metadata": {
                        **result["metadata"],
                        "sample_rate": 16000,
                        "processed_at": datetime.now().isoformat(),
                        "processing_time": processing_time,
                        "processing_mode": "real_ml_models",
                        "config": {
                            "enable_gpu": request.enable_gpu,
                            "segment_length": 5.0,
                            "language": request.language,
                            "unified_model": "whisperx-base-with-diarization",
                        },
                        "subtitle_optimization": True,
                    },
                    "speakers": result["speakers"],
                    "segments": result["segments"],
                    "processing_time": processing_time,
                    "error": None,
                    "error_code": None,
                }

                # ì™„ë£Œ ì§„í–‰ìƒí™©
                await send_callback(
                    job_id, "processing", progress_steps[5][0], progress_steps[5][1]
                )

                logger.info(f"ì „ì‚¬ ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
                logger.info(f"ë°˜í™˜í•  ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(detailed_result['segments'])}")

                return detailed_result

            except Exception as analysis_error:
                logger.error(f"ë¶„ì„ ì‹¤íŒ¨: {analysis_error}")
                processing_time = (datetime.now() - start_time).total_seconds()

                return {
                    "success": False,
                    "error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(analysis_error)}",
                    "error_code": "ANALYSIS_ERROR",
                    "processing_time": processing_time,
                }

    except Exception as e:
        processing_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"ì „ì‚¬ ìš”ì²­ ì‹¤íŒ¨ - Error: {str(e)}")

        return {
            "success": False,
            "error": f"ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
            "error_code": "REQUEST_ERROR",
            "processing_time": processing_time,
        }


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}


@app.get("/jobs/{job_id}")
async def get_job_status(job_id: str):
    """Get job status"""
    if job_id not in jobs:
        raise HTTPException(status_code=404, detail="Job not found")
    return jobs[job_id]


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ECG Audio Analyzer ML API Server")
    parser.add_argument("--host", default="0.0.0.0", help="ë°”ì¸ë“œ í˜¸ìŠ¤íŠ¸")
    parser.add_argument("--port", type=int, default=8080, help="ë°”ì¸ë“œ í¬íŠ¸")
    parser.add_argument("--workers", type=int, default=1, help="ì›Œì»¤ ìˆ˜")
    parser.add_argument(
        "--log-level", default="info", choices=["debug", "info", "warning", "error"]
    )

    args = parser.parse_args()

    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=getattr(logging, args.log_level.upper()),
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    logger.info("ğŸš€ ECG Audio Analyzer ML API ì„œë²„ ì‹œì‘")
    logger.info(f"   í˜¸ìŠ¤íŠ¸: {args.host}:{args.port}")
    logger.info(f"   ì›Œì»¤ ìˆ˜: {args.workers}")
    logger.info(f"   ë¡œê·¸ ë ˆë²¨: {args.log_level}")
    logger.info(f"   ë°±ì—”ë“œ URL: {BACKEND_URL if BACKEND_URL else 'Not configured'}")
    logger.info(f"   ì½œë°± í™œì„±í™”: {ENABLE_CALLBACKS}")

    # GPU í™•ì¸
    try:
        import torch

        if torch.cuda.is_available():
            logger.info(f"   GPU: {torch.cuda.device_count()}ê°œ ì‚¬ìš© ê°€ëŠ¥")
            for i in range(torch.cuda.device_count()):
                logger.info(f"     - GPU {i}: {torch.cuda.get_device_name(i)}")
        else:
            logger.warning("   GPU: ì‚¬ìš© ë¶ˆê°€ (CPU ëª¨ë“œ)")
    except ImportError:
        logger.warning("   PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")

    # FastAPI ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        app,
        host=args.host,
        port=args.port,
        workers=args.workers,
        access_log=True,
        log_level=args.log_level,
    )
